{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 4: NumPy, Pandas, seaborn & SciPy\n",
    "\n",
    "Last week, you learned about functions and external modules in python - this week, we'll introduce you to some of the most powerful external modules for data analysis in python, and we'll show you how you can start using them to write an entire analysis pipeline for your data set. \n",
    "\n",
    "We'll use the Titanic data set throughout this week's session, which you can learn more about here: https://www.kaggle.com/c/titanic/\n",
    "\n",
    "## 4.0 NumPy\n",
    "\n",
    "Numpy is short for \"Numerical Python\", and that's basically what it is: a Python module to help you efficiently handle numerical data in Python. It contains, among many other things, functionalities that allow you to work with matrices and N-dimensional arrays, as well as built-in functions for linear algebra and random number capabilities.  \n",
    "The documentation is located at https://docs.scipy.org/doc/numpy-1.13.0/reference/.\n",
    "\n",
    "By convention, numpy is imported as _np_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.0 NumPy arrays\n",
    "\n",
    "NumPy arrays offer a very efficient way of storing data in an array structure, and they also provide useful operations for these arrays. We'll provide a very brief introduction to NumPy arrays and the things they allow you to do here, but feel free to read more in the documentation! :)\n",
    "\n",
    "There are several straight-forward ways of creating a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of a list\n",
    "int_array = np.array([1,2,3,4,5])\n",
    "print(int_array)\n",
    "\n",
    "# Create a 1*10 float array filled with zeros\n",
    "zero_array = np.zeros(10, dtype=float)\n",
    "print(zero_array)\n",
    "\n",
    "# Create a 3x5 integer array filled with ones\n",
    "ones_array = np.ones((3, 5), dtype=int)\n",
    "print(ones_array)\n",
    "\n",
    "# Create a 5x5 array filled with random numbers between 0 and 1\n",
    "random_array = np.random.random((3,5))\n",
    "print(random_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks suspiciously similar to a \"normal\" python list, but NumPy arrays are actually a lot more memory-efficient and better at handling multidimensional data. \n",
    "\n",
    "### 4.0.1 Array attributes\n",
    "\n",
    "Each NumPy arrays comes with three attributes: _ndim_, _shape_, and _size_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of dimensions: \", ones_array.ndim)       # the number of dimensions in the array\n",
    "print(\"size of each dimension: \", ones_array.shape)    # the size of each dimension in the array\n",
    "print(\"size of the entire array: \", ones_array.size)   # the size of the entire array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.2 Indexing arrays\n",
    "\n",
    "One-dimensional arrays can be indexed very similarly to \"normal\" lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_array[2:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a multi-dimensional array, you access a specific value by using comma-separated indeces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array[0,2] # this returns row 0, column 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also edit entries using the same notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array[0,2] = 0.18\n",
    "print(random_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to access a specific subset of a NumPy array, you can use slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_array[:2, :3]) # subset the first two rows and the first three columns of the original array\n",
    "print(random_array[0, :])   # subset the entire first row of the original array\n",
    "print(random_array[:, 1])   # subset the entire first column of the original array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.3 Combining arrays\n",
    "\n",
    "NumPy allows you to combine arrays in different dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.array([1,2,3])\n",
    "array2 = np.array([4,5,6])\n",
    "\n",
    "array3 = np.vstack([array1, array2]) # stack \"vertically\"\n",
    "array4 = np.hstack([array1, array2]) # stack \"horizontally\"\n",
    "\n",
    "print(array3)\n",
    "print(array4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.4 Operating on arrays\n",
    "\n",
    "As we mentioned earlier, NumPy comes with several useful functions, some of which operate a lot faster than \"normal\" python built-ins. For example, let's compare how fast NumPy's sum function is compared to the original built-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_array = np.random.rand(1000000)\n",
    "%timeit sum(big_array)\n",
    "%timeit np.sum(big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's almost twice as fast! The same goes for min, max, and other functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit min(big_array)\n",
    "%timeit np.min(big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot more to NumPy, but most of it you'll find out as you go along and use it. And there's a very useful, in-depth chapter about NumPy in the \"Python Data Science Handbook\" here: https://jakevdp.github.io/PythonDataScienceHandbook/02.00-introduction-to-numpy.html We highly recommend going through this in your own time if you want to learn about NumPy in more depth. \n",
    "\n",
    "For the purpose of this very brief introduction, let's just acknowledge that NumPy offers a lot of useful ways of dealing with multi-dimensional arrays and numerical data. Speaking of data... let's actually import a data set! We'll use Pandas for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Pandas\n",
    "\n",
    "Pandas is a python library built \"on top\" of NumPy, extending NumPy's functionality quite a bit.  \n",
    "Docs are at https://pandas.pydata.org/pandas-docs/stable/. These docs are markedly worse than for most Python modules, but luckily pandas is usually pretty easy to use.\n",
    "\n",
    "By convention, pandas is imported as pd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main objects you'll be dealing with in pandas are Series and DataFrames. These are similar to NumPy arrays, but they include labeled rows and columns, and they allow heterogenous data types and missing values. Here is a quick example of how to initialize a Series and a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series = pd.Series([1,2,3,'four',[5,6,7]])\n",
    "print(test_series)\n",
    "test_df = pd.DataFrame(random_array)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but usually, we'd prefer not to manually enter our data into our data frame, so let's import an actual data set.\n",
    "\n",
    "### 4.1.0 Reading a data set into python using pandas\n",
    "\n",
    "The data set we'll be using is the Titanic data set. It contains data about the passengers of the Titanic, and it's one of the most widely used open data sets for learning data science and machine learning (see https://www.kaggle.com/c/titanic for a more in-depth description, plus some fun examples of how others have analysed this data set before). For the purpose of today's session, we will simply explore this data set a little and find out how NumPy, pandas, seaborn and SciPy allow us to handle the data\n",
    "\n",
    "Here's how you read a data set into pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the pd.read_csv function to read in a comma-separated file\n",
    "titanic = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preview the data\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .head() method allows us to get a peak of our data without having to print all of it to the screen. Pretty useful! \n",
    "\n",
    "From this preview, we can see the types of information that are included in the data set. For example, there are columns with information about whether or not the passenger survived (0 or 1), the class they travelled in (1,2,3), their name, gender, and age, and how much they paid for their ticket. We also get information about how many siblings or spouses were with them (SibSp), and how many parents and children (Parch). \"Embarked\" is an abbreviation for the harbour at which the passenger embarked.\n",
    "\n",
    "For further steps of the analysis, it would be useful to know the data types of the values in each column. pandas allows you to display a summary of this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us the type of each of the columns. PassengerId, for example, appears to be an integer. This also tells us that there are 891 entries in our data frame. Most columns seem to be \"complete\" (i.e., they have 891 values), but others, such as Age and Cabin, seem to have missing values. \n",
    "\n",
    "There's another, more explicit way of looking for missing values in pandas DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.isnull().sum() # the sum() method summarizes all the missing values for each column\n",
    "# you can leave it out if you would like an explicit overview of all the values in the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this tells us that there are 177 missing values in the Age column, 687 in the cabin column, and 2 in the Embarked column.\n",
    "\n",
    "Another way of getting a more detailed summary of the numerical data is the .describe method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a neat overview of some interesting bits of information in our data (although beware that this is really just a \"general idea\", because we know already that we have missing data in some cases). \n",
    "\n",
    "### 4.1.1 Accessing pandas DataFrames\n",
    "\n",
    "What if you wanted to access only specific subsets of the titanic data frame? Here's one way of doing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age'].head() # leave out the \".head()\" method if you really want the entire column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Age.head() # and this is an even easier way of accessing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also filter the data frame based on conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic['Age'] > 18].head()\n",
    "# or:\n",
    "titanic[titanic.Age > 18].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use \\& (and) and \\| (or) to refine your filter even further.\n",
    "\n",
    "It's also possible to sort your columns in different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.sort_values('Name', ascending=False).head() # sorts descending\n",
    "titanic.sort_values('Name').head() # sorts ascending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Data cleaning\n",
    "\n",
    "As we saw earlier, there are a few missing values in our data set, which can be a little annoying during further steps. Some of the columns containing missing values might not actually be all that important for our analyses, so we can drop them all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop(['Cabin'], axis = 1) # the axis argument tells pandas that we want to drop the COLUMNS. \n",
    "# the default is axis = 0, which would drop the ROWS.\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility would be to fill in the missing values - this might not always be a good idea, but let's just assume for now that you have a good reason to do this. For example, you could fill all the missing values in a given column with the mean of that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill each missing value in the Age column with the mean of the Age column\n",
    "titanic.Age = titanic.Age.fillna(titanic.Age.mean())\n",
    "titanic.head()\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .isnull method tells us that we now don't have any further missing values, except for two values in the 'Embarked' column. Let's just drop the rows containing these missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.dropna()\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we got rid of all the missing values! Now imagine you wanted to change the values of the 'Survived' column to 'yes' and 'no', rather than 1 and 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Survived = titanic.Survived.replace([1,0], ['yes','no'])\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also easily rename the columns, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.rename(columns={'Parch': 'ParCh'})\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to join several data frames together. For example, imagine you had a different data frame with all the passenger IDs, plus whether they were left- or right-handed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a random data frame\n",
    "handedness = pd.DataFrame(index = range(0,891), columns = ['Handedness', 'PassengerId'])\n",
    "handedness.Handedness = np.random.choice([1,0], len(handedness))\n",
    "handedness.PassengerId = np.arange(1,892)\n",
    "handedness.info()\n",
    "handedness.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.concat([titanic, handedness], axis=1).head() # axis = 1 tells pandas that we want to concatenate columns, not rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've done all that work on the Titanic dataset, we'll want to preserve it by writing it to a file. Pandas has a convenient way to do this for dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.to_csv('titanic_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.2 Seaborn\n",
    "Seaborn is a plotting library, similar to ggplot in R. Basic plotting with Seaborn is very easy, but as with ggplot, it has many options for altering and extending figures and it's easy to get lost in the details. Today we will only cover some of the basics, but Seaborn has excellent documentation, so if you want to know more, go to https://seaborn.pydata.org/.  \n",
    "To get started, let's just import seaborn and draw a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  # convention is to import seaborn under the name sns, for unclear reasons\n",
    "\n",
    "# some magic that will make this notebook display our plots inline, don't worry about this for now\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# make up some x and y values\n",
    "x = np.linspace(0, 10)\n",
    "y = x * x\n",
    "\n",
    "# and plot using the lineplot method\n",
    "sns.lineplot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was rather easy, but let's plot something more interesting.  \n",
    "Using the Titanic data, we can plot the relationship between different variables and survival rate. Let's start with age. The obvious way to plot this is using a violinplot or something similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn has a violinplot method, so this will be fairly easy\n",
    "sns.violinplot(x='Survived', y='Age', data=titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks fairly similar between the yes and no groups, except for a little bump just above age 0 in the survived group. It seems like they may have made an effort to put children on the lifeboats first.  \n",
    "That makes me wonder if women were sent to the lifeboats before men. Let's plot that and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Survived', hue='Sex', data=titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that seems like quite a difference.  \n",
    "There were three classes of ticket sold on the Titanic. Using the `countplot()` method, plot the survival numbers for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot surivival counts for each class here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While survival is the most salient part of this dataset, there are of course other things we can plot that might be of interest. For instance, what is the relationship between price of the ticket (_fare_) and age?  \n",
    "Plot this using a scatterplot. (Hint: It's the `scatterplot()` method!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot age by ticket price here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not very easy to interpret by sight. Let's add a trendline using linear regression.  \n",
    "The plotting method for this is called `regplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot using regplot here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 SciPy\n",
    "Because we have limited time to go over everything, we're not going to do anything about SciPy other than to say: SciPy is essentially an extension of NumPy. If you can't find some kind of numerical operation you need in NumPy, SciPy might have it. (If you're going to do weird statistics or EEG/MEG/fMRI analysis, you might need SciPy's signal processing or linear algebra functions at some point.)  \n",
    "Documentation is pretty good and is located at https://docs.scipy.org/doc/scipy/reference/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 DIY time!\n",
    "Feel free to mess around with the Titanic dataset some more, exploring it in different ways by grouping and plotting data. When you feel like you want another challenge, move on to this week's additional exercises."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
