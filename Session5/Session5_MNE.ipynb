{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5.0 A very brief intro to MNE\n",
    "\n",
    "\n",
    "\n",
    "MNE is an open-source software package to help you analyze and visualize M/EEG, ECoG, and other types of neurophysiological data. Things you can do in MNE include:\n",
    "\n",
    "* visualizing data\n",
    "* epoching\n",
    "* averaging and computing evoked responses\n",
    "* computing ICA \n",
    "* time-frequency analysis\n",
    "* computing connectivity estimates\n",
    "* classifier analysis \n",
    "* non-parametric stats\n",
    "\n",
    "...and many more. There's a wealth of documentation (https://mne.tools/stable/overview/index.html) and examples (https://mne.tools/stable/auto_examples/index.html) online. \n",
    "\n",
    "In today's session, we'll briefly walk you through one of the MNE introductory examples so you can get a general feel for how to use MNE. \n",
    "\n",
    "Here's the original example that we'll be using: https://mne.tools/stable/auto_tutorials/intro/plot_10_overview.html#sphx-glr-auto-tutorials-intro-plot-10-overview-py. We'll plot evoked responses today, but the original example also shows you how to run and plot a time-frequency analysis and a bunch of other cool things. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Installing MNE\n",
    "\n",
    "Downloading and installing MNE can take a little time, so for the purpose of today's session (or if you're generally not that interested in analyzing M/EEG data), we'd advise you to just follow along with the lecture from here on out, rather than downloading and installing the package and example data set.\n",
    "\n",
    "Installation instructions can be found here: https://mne.tools/stable/install/index.html. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Reading in raw data\n",
    "\n",
    "Once you have MNE installed, you can already read in your raw data! MNE supports several different data formats, including fif, brainvision, eeglab, and edf files. You can read more about that here: https://martinos.org/mne/stable/manual/io.html\n",
    "\n",
    "The example we're using works with MNE's sample data set, which comes as fif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "sample_data_raw_file = os.path.join(sample_data_folder, 'MEG', 'sample',\n",
    "                                    'sample_audvis_filt-0-40_raw.fif')\n",
    "raw = mne.io.read_raw_fif(sample_data_raw_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a lot of useful information about our raw data: We can see that there are 376 channels (chs and nchan), what they're called (ch_names), the events (0 at this point, because we haven't defined them yet), channels marked as bad (MEG 2443 and EEG 053, apparently), highpass and lowpass filters that have been applied (0.1 Hz and 40 Hz), the sampling frequency (sfreq), and a lot more. We can look at each of these in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for example, look at the channel names\n",
    "print(raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or look at the bad channels\n",
    "print(raw.info['bads'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Browsing raw data\n",
    "\n",
    "Now let's have a look at a segment of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Note that usually, when using MNE outside of jupyter notebooks, \n",
    "this will open an interactive window where you can scroll through your data \n",
    "and, for example, mark bad channels manually.\n",
    "\n",
    "For now, we'll just show a preview of what that looks like.'''\n",
    "\n",
    "raw.plot_psd(fmax=50) # plot up to 50 Hz\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read more about how to browse raw data in MNE here: https://mne.tools/stable/auto_tutorials/raw/plot_40_visualize_raw.html?highlight=browse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Preprocessing / ICA\n",
    "\n",
    "You can use Independent Component Analysis (ICA) in mne. In the code snippet below (from the mne documentation), it is assumed that you already know which components to inspect (i.e., components 1 and 2). Usually, you'll have to take a few more steps to determine which components capture the artifacts best (https://mne.tools/stable/auto_tutorials/preprocessing/plot_40_artifact_correction_ica.html#tut-artifact-ica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800)\n",
    "ica.fit(raw)\n",
    "ica.exclude = [1, 2]  # details on how we picked these are omitted here\n",
    "ica.plot_properties(raw, picks=ica.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# back-project ICA to the raw signal\n",
    "\n",
    "orig_raw = raw.copy()\n",
    "raw.load_data()\n",
    "ica.apply(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Epoching data\n",
    "\n",
    "MNE can extract events for you like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use function .find_events on the raw data\n",
    "# and tell MNE that your stimulus channel is called 'STI 014'\n",
    "events = mne.find_events(raw, stim_channel='STI 014')\n",
    "\n",
    "# look at the first five events\n",
    "print(events[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recode events for clarity\n",
    "\n",
    "event_dict = {'auditory/left': 1, 'auditory/right': 2, 'visual/left': 3,\n",
    "              'visual/right': 4, 'smiley': 5, 'buttonpress': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to exclude some noisy channels, you can save all the bad channels in a list, pass that list to MNE, and select only the remaining good channels, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw.info['bads'] += ['MEG 2443', 'EEG 053']\n",
    "picks = mne.pick_types(raw.info, meg=True, eeg=True, eog=True, stim=False,\n",
    "                       exclude='bads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data frame 'picks' includes all the MEG, EEG and EOG channels, excluding the ones that are in your list of 'bad' channels and the STIM channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define parameters for epoching\n",
    "\n",
    "# first, define rejection criteria\n",
    "reject_criteria = dict(mag=4000e-15,     # 4000 fT\n",
    "                       grad=4000e-13,    # 4000 fT/cm\n",
    "                       eeg=150e-6,       # 150 μV\n",
    "                       eog=250e-6)       # 250 μV\n",
    "\n",
    "# epoch the data\n",
    "epochs = mne.Epochs(raw, events, event_id=event_dict, tmin=-0.2, tmax=0.5,\n",
    "                    reject=reject_criteria, preload=True)\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the epochs data frame now includes different conditions: 'auditory/left', 'visual/left', and so on. mne also gives you a summary of how many trials there are per condition. In a next step, you could pool across left/right stimulus presentation to compare auditory to visual trials: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conds_we_care_about = ['auditory/left', 'auditory/right',\n",
    "                       'visual/left', 'visual/right']\n",
    "epochs.equalize_event_counts(conds_we_care_about)  # this operates in-place\n",
    "aud_epochs = epochs['auditory']\n",
    "vis_epochs = epochs['visual']\n",
    "del raw, epochs  # free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you could plot evoked responses for auditory and visual responses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aud_evoked = aud_epochs.average()\n",
    "vis_evoked = vis_epochs.average()\n",
    "\n",
    "mne.viz.plot_compare_evokeds(dict(auditory=aud_evoked, visual=vis_evoked),\n",
    "                             legend='upper left', show_sensors='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There really is .A LOT. more you can do with MNE, but the techniques you'll be using obviously depend a lot on your research question and data. If you're interested in using MNE for data analysis, we can't recommend their documentation, tutorials, and example gallery enough! (See links in section X.0). Have fun! :) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
